{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franco/Desktop/TESIS/Code/ThesisModel/tesis-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Tokenizer, Trainer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "# We reload the saved dataset that was preprocessed in dataset-prep notebook.\n",
    "dataset = load_from_disk('preprocessed-dataset-latex')\n",
    "\n",
    "# We upload the T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"vgaraujov/t5-base-spanish\")\n",
    "\n",
    "# We upload the T5 pretrained model base\n",
    "model = T5ForConditionalGeneration.from_pretrained('vgaraujov/t5-base-spanish')\n",
    "#model = T5ForConditionalGeneration.from_pretrained('./results/latex')\n",
    "#model = T5ForConditionalGeneration.from_pretrained('./results/latex-ner')\n",
    "#model = T5ForConditionalGeneration.from_pretrained('./results/latex-trees')\n",
    "#model = T5ForConditionalGeneration.from_pretrained('./results/complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# Crear el entrenador\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    tokenizer=tokenizer,                 \n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42156eb43b6144eea8f4e86f3dea6e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([[[ 1.2773583 ,  3.8190114 ,  2.9986262 , ..., -4.46272   ,\n",
       "         -3.5805202 ,  0.6499685 ],\n",
       "        [-0.86647874,  1.6427323 ,  4.147688  , ..., -2.5420032 ,\n",
       "         -3.117785  , -0.57773197],\n",
       "        [-1.1411113 , -1.4236448 ,  5.5018215 , ..., -2.6014123 ,\n",
       "         -1.9399649 , -0.5542981 ],\n",
       "        ...,\n",
       "        [ 1.171685  ,  3.9959712 ,  2.9309154 , ..., -4.278045  ,\n",
       "         -3.4396124 ,  0.6063939 ],\n",
       "        [ 1.1720676 ,  3.9956298 ,  2.9312243 , ..., -4.279063  ,\n",
       "         -3.440767  ,  0.6068993 ],\n",
       "        [ 1.172512  ,  3.9960682 ,  2.931536  , ..., -4.279534  ,\n",
       "         -3.4414701 ,  0.6078959 ]],\n",
       "\n",
       "       [[ 1.2749777 ,  3.805031  ,  3.0213141 , ..., -4.4991283 ,\n",
       "         -3.61095   ,  0.6595073 ],\n",
       "        [-1.7859082 ,  1.294733  ,  3.9292848 , ..., -2.2316995 ,\n",
       "         -4.53111   ,  0.09840891],\n",
       "        [-1.5912012 ,  2.468893  ,  5.9766603 , ..., -3.5110373 ,\n",
       "         -3.4888043 , -1.1441418 ],\n",
       "        ...,\n",
       "        [ 1.1857646 ,  3.9724526 ,  2.9762259 , ..., -4.3595805 ,\n",
       "         -3.510021  ,  0.6299285 ],\n",
       "        [ 1.1861725 ,  3.9715297 ,  2.9764817 , ..., -4.360344  ,\n",
       "         -3.5108657 ,  0.6301716 ],\n",
       "        [ 1.1863608 ,  3.9720168 ,  2.9768775 , ..., -4.3612165 ,\n",
       "         -3.511587  ,  0.6301821 ]],\n",
       "\n",
       "       [[ 1.2655084 ,  3.8184762 ,  2.99912   , ..., -4.468751  ,\n",
       "         -3.595482  ,  0.65470207],\n",
       "        [-0.33471718,  2.3166857 ,  3.785569  , ..., -2.8301592 ,\n",
       "         -2.8894653 , -0.10159941],\n",
       "        [ 0.36674446, -2.6266131 ,  7.108561  , ..., -2.4502034 ,\n",
       "         -1.4576713 , -0.80548644],\n",
       "        ...,\n",
       "        [ 1.14787   ,  4.007656  ,  2.9370039 , ..., -4.2949705 ,\n",
       "         -3.4690127 ,  0.60746795],\n",
       "        [ 1.1484592 ,  4.0069685 ,  2.9372628 , ..., -4.2964272 ,\n",
       "         -3.4705036 ,  0.6078841 ],\n",
       "        [ 1.1492678 ,  4.0053883 ,  2.9374628 , ..., -4.297307  ,\n",
       "         -3.4714694 ,  0.60856384]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.2814875 ,  3.840009  ,  2.9835641 , ..., -4.467666  ,\n",
       "         -3.5985966 ,  0.6509978 ],\n",
       "        [-0.46200147,  2.0426679 ,  3.123138  , ..., -2.8601289 ,\n",
       "         -3.2232363 ,  0.07001589],\n",
       "        [-0.12688717, -1.5190483 ,  4.97167   , ..., -1.6465997 ,\n",
       "         -1.9794906 , -0.9180011 ],\n",
       "        ...,\n",
       "        [ 1.1842626 ,  4.0261283 ,  2.9167693 , ..., -4.321545  ,\n",
       "         -3.5119026 ,  0.62221885],\n",
       "        [ 1.1841621 ,  4.025644  ,  2.9165876 , ..., -4.321743  ,\n",
       "         -3.5123966 ,  0.6228347 ],\n",
       "        [ 1.1843765 ,  4.0254107 ,  2.916835  , ..., -4.3218737 ,\n",
       "         -3.5129046 ,  0.62369585]],\n",
       "\n",
       "       [[ 1.2127876 ,  3.883941  ,  3.009698  , ..., -4.4644756 ,\n",
       "         -3.5679173 ,  0.6583696 ],\n",
       "        [-0.9286251 ,  0.57338953,  5.754511  , ..., -2.9267921 ,\n",
       "         -2.93758   , -1.4973363 ],\n",
       "        [-0.5221096 , -0.52488047,  5.5254703 , ..., -2.2191172 ,\n",
       "         -2.1756506 , -0.2626125 ],\n",
       "        ...,\n",
       "        [ 1.0727452 ,  3.9707568 ,  2.9500666 , ..., -4.2820005 ,\n",
       "         -3.439947  ,  0.60558057],\n",
       "        [ 1.0730395 ,  3.9682355 ,  2.950132  , ..., -4.2821136 ,\n",
       "         -3.4400218 ,  0.60532373],\n",
       "        [ 1.0732483 ,  3.9670022 ,  2.9502642 , ..., -4.2823024 ,\n",
       "         -3.440245  ,  0.60526687]],\n",
       "\n",
       "       [[ 1.2716272 ,  3.8065977 ,  2.988175  , ..., -4.4670963 ,\n",
       "         -3.601668  ,  0.6394601 ],\n",
       "        [-0.7848328 ,  1.6188494 ,  3.277319  , ..., -2.4913867 ,\n",
       "         -3.3612306 , -0.28379196],\n",
       "        [-0.40042633, -1.6015457 ,  5.1897287 , ..., -2.0315993 ,\n",
       "         -2.360929  , -0.6760115 ],\n",
       "        ...,\n",
       "        [ 1.1974621 ,  3.9271622 ,  2.9376407 , ..., -4.3395495 ,\n",
       "         -3.5229142 ,  0.6176247 ],\n",
       "        [ 1.1971546 ,  3.9241729 ,  2.9373267 , ..., -4.3407726 ,\n",
       "         -3.5234246 ,  0.6184962 ],\n",
       "        [ 1.1969656 ,  3.9185567 ,  2.9366446 , ..., -4.342208  ,\n",
       "         -3.5229762 ,  0.6191372 ]]], dtype=float32), array([[[ 0.1612692 , -0.05447076,  0.03535091, ...,  0.02681072,\n",
       "         -0.17888412,  0.04772572],\n",
       "        [-0.18792427, -0.13735278,  0.2965378 , ..., -0.24730308,\n",
       "          0.14751925,  0.00597166],\n",
       "        [ 0.11840409, -0.11236095,  0.04292814, ..., -0.1160502 ,\n",
       "          0.24911241,  0.06344327],\n",
       "        ...,\n",
       "        [ 0.16212419,  0.19265176,  0.22188   , ..., -0.04591753,\n",
       "         -0.00156124,  0.05454571],\n",
       "        [ 0.16212419,  0.19265176,  0.22188   , ..., -0.04591753,\n",
       "         -0.00156124,  0.05454571],\n",
       "        [ 0.16212419,  0.19265176,  0.22188   , ..., -0.04591753,\n",
       "         -0.00156124,  0.05454571]],\n",
       "\n",
       "       [[ 0.00544636, -0.18847737,  0.14899407, ..., -0.1561541 ,\n",
       "         -0.39347598,  0.04409577],\n",
       "        [-0.19693033, -0.21426502,  0.31586266, ..., -0.34503922,\n",
       "         -0.06987107,  0.05331072],\n",
       "        [ 0.10665406,  0.03431027,  0.11604978, ..., -0.08103409,\n",
       "          0.03815039,  0.03895787],\n",
       "        ...,\n",
       "        [-0.16837715, -0.18419693,  0.14728549, ..., -0.29656795,\n",
       "          0.03483984,  0.12788428],\n",
       "        [-0.16837715, -0.18419693,  0.14728549, ..., -0.29656795,\n",
       "          0.03483984,  0.12788428],\n",
       "        [-0.16837715, -0.18419693,  0.14728549, ..., -0.29656795,\n",
       "          0.03483984,  0.12788428]],\n",
       "\n",
       "       [[ 0.14709301,  0.058576  ,  0.14946207, ..., -0.17536794,\n",
       "         -0.12482966,  0.0235429 ],\n",
       "        [-0.08072964, -0.2528302 ,  0.19595252, ..., -0.5308622 ,\n",
       "          0.031317  ,  0.00828761],\n",
       "        [ 0.09151985, -0.07154394,  0.00505877, ..., -0.1552164 ,\n",
       "          0.14397918,  0.05733063],\n",
       "        ...,\n",
       "        [ 0.12553078,  0.1956351 ,  0.19738086, ..., -0.00313962,\n",
       "         -0.18467087,  0.02183276],\n",
       "        [ 0.12553078,  0.1956351 ,  0.19738086, ..., -0.00313962,\n",
       "         -0.18467087,  0.02183276],\n",
       "        [ 0.12553078,  0.1956351 ,  0.19738086, ..., -0.00313962,\n",
       "         -0.18467087,  0.02183276]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.03964895, -0.09787057,  0.24923646, ..., -0.01105422,\n",
       "         -0.06569033, -0.00651814],\n",
       "        [-0.06244211, -0.14609891,  0.36568365, ..., -0.2854492 ,\n",
       "          0.2652158 , -0.02298286],\n",
       "        [-0.02045696, -0.15594362,  0.06173249, ..., -0.13605905,\n",
       "          0.21158896,  0.03471805],\n",
       "        ...,\n",
       "        [ 0.06902857,  0.08807803,  0.23480266, ...,  0.10424668,\n",
       "         -0.06364316,  0.00653221],\n",
       "        [ 0.06902857,  0.08807803,  0.23480266, ...,  0.10424668,\n",
       "         -0.06364316,  0.00653221],\n",
       "        [ 0.06902857,  0.08807803,  0.23480266, ...,  0.10424668,\n",
       "         -0.06364316,  0.00653221]],\n",
       "\n",
       "       [[-0.06428114, -0.12015492,  0.09338547, ...,  0.04967137,\n",
       "         -0.08950594,  0.03780685],\n",
       "        [-0.25368407, -0.23677872,  0.18428615, ..., -0.38469157,\n",
       "          0.28957084, -0.02006811],\n",
       "        [-0.06077951, -0.09909298, -0.10791412, ..., -0.05525179,\n",
       "          0.12262632,  0.02259784],\n",
       "        ...,\n",
       "        [ 0.09681882, -0.00822534,  0.22936389, ...,  0.02038791,\n",
       "          0.13189358,  0.02041145],\n",
       "        [ 0.09681882, -0.00822534,  0.22936389, ...,  0.02038791,\n",
       "          0.13189358,  0.02041145],\n",
       "        [ 0.09681882, -0.00822534,  0.22936389, ...,  0.02038791,\n",
       "          0.13189358,  0.02041145]],\n",
       "\n",
       "       [[ 0.23577423, -0.03336691,  0.05833161, ...,  0.06307893,\n",
       "         -0.22202957,  0.08628016],\n",
       "        [-0.11758405, -0.22524033,  0.27513528, ..., -0.49711135,\n",
       "          0.0978239 ,  0.01940274],\n",
       "        [ 0.1283277 , -0.10013697,  0.01749064, ..., -0.14340737,\n",
       "          0.18374054,  0.06862789],\n",
       "        ...,\n",
       "        [ 0.06876672,  0.13054988,  0.41383418, ..., -0.0026144 ,\n",
       "         -0.15980561,  0.12723486],\n",
       "        [ 0.06876672,  0.13054988,  0.41383418, ..., -0.0026144 ,\n",
       "         -0.15980561,  0.12723486],\n",
       "        [ 0.06876672,  0.13054988,  0.41383418, ..., -0.0026144 ,\n",
       "         -0.15980561,  0.12723486]]], dtype=float32)), label_ids=array([[  175,   972,  1270, ...,  -100,  -100,  -100],\n",
       "       [20281,  1136,  8496, ...,  -100,  -100,  -100],\n",
       "       [  175,   972,   480, ...,  -100,  -100,  -100],\n",
       "       ...,\n",
       "       [  175, 21872,   175, ...,  -100,  -100,  -100],\n",
       "       [  972,  1270,   598, ...,  -100,  -100,  -100],\n",
       "       [  175,   972,  1270, ...,  -100,  -100,  -100]]), metrics={'test_loss': 6.9929938316345215, 'test_model_preparation_time': 0.0053, 'test_runtime': 58.7502, 'test_samples_per_second': 2.434, 'test_steps_per_second': 0.306})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generar pseudolatex: Polinomio de grado 7 completo con coeficientes enteros', 'generar pseudolatex: Sistema de tres ecuaciones. Una de ellas de tres variables y las dos restantes de dos variables o incógnitas.', 'generar pseudolatex: Polinomio completo de séptimo grado con todos sus coeficientes decimales negativos. El polinomio está ordenado en orden descendente', 'generar pseudolatex: un polinomio de noveno grado incompleto con variable z', 'generar pseudolatex: Sistema de ecuaciones', 'generar pseudolatex: Sistema de ecuacion de 2 ecuaciones lineales de dos variables, con coeficientes distintos de 0', 'generar pseudolatex: Polinomio de grado 1 incompleto con 1 término', 'generar pseudolatex: polinomio de grado 4 con cinco terminos', 'generar pseudolatex: Sistema de ecuaciones homogeneo', 'generar pseudolatex: Sistema de ecuaciones de 4 incógnitas y dos ecuaciones, compatible indeterminado', 'generar pseudolatex: Polinomio con coeficientes complejo y naturales, de noveno grado e incompleto. Tiene 5 términos', 'generar pseudolatex: Polinomio de grado 15, con siete términos, y todos ellos restando', 'generar pseudolatex: Polinomio de grado uno incompleto con uno término', 'generar pseudolatex: Polinomio en orden ascendente de potencias de quinto grado con valores fraccionarios', 'generar pseudolatex: Sist. de ecuaciones, dos variables, dos ecuaciones. Homogeneo', 'generar pseudolatex: Una expresión polinomica de grado 4, con coeficiente principal 38.3, coeficiente de grado 3 de 1.5, coeficiente de grado 2 de 6.3, coeficiente primer grado de 13.1 y termino independiente de 4', 'generar pseudolatex: sistema de ecuaciones de 2 ecuaciones igualadas a 0, con 2 incognitas', 'generar pseudolatex: Polinomio incompleto de cuarto grado en indeterminada \"y\", le falta solo el termino independiente. El coeficiente principal es un número complejo', 'generar pseudolatex: Polinomio séptimo grado ordendo de forma de grado decreciente']\n"
     ]
    }
   ],
   "source": [
    "descriptions = dataset['test']['input'][0:19]\n",
    "inputs = tokenizer(descriptions, return_tensors='pt', padding=True)\n",
    "\n",
    "print(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(inputs=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_new_tokens=200)\n",
    "decodings = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = './test-logs/outputs-base.csv'\n",
    "\n",
    "results = {'inputs': descriptions, 'outputs': decodings}\n",
    "\n",
    "pd.DataFrame(data=results).to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
